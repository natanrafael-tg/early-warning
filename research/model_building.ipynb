{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e8d239e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building risk score on Harvard's foundation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Building risk score on Harvard's foundation\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cfe500f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing data types and identifying key features...\n",
      "Dataset shape: (4056, 114)\n",
      "RG Cases: 2042 (50.3%)\n"
     ]
    }
   ],
   "source": [
    "# Fix data type issues and identify key behavioral features\n",
    "\n",
    "def fix_data_types(df):\n",
    "    print(\"Fixing data types and identifying key features...\")\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = pd.to_numeric(df[col], errors='ignore')\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = pd.read_csv(\"../../early/AnalyticDataSet_Braverman_LaPlante_PAB_2013.dat.txt\", delimiter='\\t', low_memory=False)\n",
    "df = fix_data_types(df)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"RG Cases: {df['RG_case'].sum()} ({df['RG_case'].mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7827bc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Identifying key behavioral features\n",
      "==================================================\n",
      "Found 3 variability features\n",
      "Found 6 cross-game features\n",
      "Found 33 temporal features\n",
      "Found 40 financial features\n"
     ]
    }
   ],
   "source": [
    "# Identify and Engineer Key Behavioral Features\n",
    "\n",
    "def identify_key_features(df):\n",
    "    print(\"\\nIdentifying key behavioral features\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Harvard's Validated Risk Groups (our baseline)\n",
    "    risk_features = ['RiskGroup1', 'RiskGroup2', 'RiskGroupCombined']\n",
    "    \n",
    "    # Variability Measures (strongest predictors according to research)\n",
    "    variability_features = [col for col in df.columns if 'SD' in col and 'Stakes' in col]\n",
    "    print(f\"Found {len(variability_features)} variability features\")\n",
    "    \n",
    "    # Cross-Game Activity Features\n",
    "    game_features = [col for col in df.columns if 'NumberofGames' in col or 'played' in col]\n",
    "    print(f\"Found {len(game_features)} cross-game features\")\n",
    "    \n",
    "    # Temporal Pattern Features\n",
    "    temporal_features = [col for col in df.columns if any(x in col for x in ['wk1', 'wk2', 'wk3', 'wk4', 'frequency', 'trajectory'])]\n",
    "    print(f\"Found {len(temporal_features)} temporal features\")\n",
    "    \n",
    "    # Financial Behavior Features\n",
    "    financial_features = [col for col in df.columns if any(x in col for x in ['sumstake', 'avgbet', 'totalactive'])]\n",
    "    print(f\"Found {len(financial_features)} financial features\")\n",
    "    \n",
    "    return {\n",
    "        'risk': risk_features,\n",
    "        'variability': variability_features[:10],  # Top 10 to avoid overfitting\n",
    "        'games': game_features,\n",
    "        'temporal': temporal_features[:15],  # Top 15\n",
    "        'financial': financial_features[:15]  # Top 15\n",
    "    }\n",
    "\n",
    "feature_groups = identify_key_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2cc5cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating features\n",
      "==============================\n",
      "Created activity escalation feature\n",
      "Created cross-game risk feature\n"
     ]
    }
   ],
   "source": [
    "# Create feature set\n",
    "\n",
    "def create_enhanced_features(df):\n",
    "    print(\"\\nCreating features\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    df_enhanced = df.copy()\n",
    "    \n",
    "    # Loss-Chasing Indicators\n",
    "    loss_cols = [col for col in df.columns if 'loss' in col.lower()]\n",
    "    if loss_cols:\n",
    "        print(f\"Found {len(loss_cols)} loss-related columns\")\n",
    "        # Create loss-chasing intensity score\n",
    "        loss_features = []\n",
    "        for col in loss_cols[:3]:\n",
    "            if df[col].dtype in ['int64', 'float64']:\n",
    "                loss_features.append(col)\n",
    "        \n",
    "        if loss_features:\n",
    "            # Normalize and combine loss features\n",
    "            for col in loss_features:\n",
    "                df_enhanced[f'{col}_normalized'] = (df[col] - df[col].mean()) / (df[col].std() + 1e-8)\n",
    "            \n",
    "            df_enhanced['loss_chasing_score'] = df_enhanced[[f'{col}_normalized' for col in loss_features]].mean(axis=1)\n",
    "    \n",
    "    # Activity Escalation Score\n",
    "    activity_cols = [col for col in df.columns if 'totalactive' in col]\n",
    "    if activity_cols:\n",
    "        df_enhanced['activity_escalation'] = df[activity_cols[0]]\n",
    "        print(\"Created activity escalation feature\")\n",
    "    \n",
    "    # Cross-Game Risk Score\n",
    "    if 'NumberofGames31days' in df.columns:\n",
    "        df_enhanced['cross_game_risk'] = df['NumberofGames31days'] / df['NumberofGames31days'].max()\n",
    "        print(\"Created cross-game risk feature\")\n",
    "    \n",
    "    # Variability Composite Score\n",
    "    variability_cols = [col for col in df.columns if 'SD' in col and 'Stakes' in col]\n",
    "    if len(variability_cols) >= 2:\n",
    "        # Normalize variability measures\n",
    "        variability_scores = []\n",
    "        for col in variability_cols[:3]:\n",
    "            if df[col].dtype in ['int64', 'float64'] and df[col].std() > 0:\n",
    "                normalized_col = (df[col] - df[col].mean()) / df[col].std()\n",
    "                variability_scores.append(normalized_col)\n",
    "        \n",
    "        if variability_scores:\n",
    "            df_enhanced['variability_composite'] = np.mean(variability_scores, axis=0)\n",
    "            print(\"Created variability composite score\")\n",
    "    \n",
    "    return df_enhanced\n",
    "\n",
    "df_enhanced = create_enhanced_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26112ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building enhanced risk model\n",
      "==================================================\n",
      "risk: 3 features\n",
      "variability: 3 features\n",
      "games: 6 features\n",
      "temporal: 15 features\n",
      "financial: 15 features\n",
      "\n",
      "Total features for modeling: 44\n",
      "Final feature set: 40 features\n",
      "Using existing validation split: 3037 train, 1019 test\n",
      "\n",
      "Model performance:\n",
      "AUC Score: 0.750\n",
      "Accuracy: 0.698\n",
      "\n",
      "Top 10 most important features:\n",
      " 1. p2sumstake31days               0.100\n",
      " 2. p2avgbetsperday                0.064\n",
      " 3. p1sumstake31days               0.064\n",
      " 4. p1avgbetsperday                0.051\n",
      " 5. p2avgbetsperactiveday          0.046\n",
      " 6. p1avgbetsperactiveday          0.045\n",
      " 7. cross_game_risk                0.041\n",
      " 8. NumberofGames31days            0.035\n",
      " 9. pcsumstake31days               0.035\n",
      "10. p2totalactivedays_31days       0.034\n"
     ]
    }
   ],
   "source": [
    "# Build enhanced risk model\n",
    "\n",
    "def build_enhanced_risk_model(df, feature_groups):\n",
    "    print(\"\\nBuilding enhanced risk model\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    all_features = []\n",
    "    for group_name, features in feature_groups.items():\n",
    "        available_features = [f for f in features if f in df.columns]\n",
    "        all_features.extend(available_features)\n",
    "        print(f\"{group_name}: {len(available_features)} features\")\n",
    "    \n",
    "    enhanced_features = ['loss_chasing_score', 'activity_escalation', 'cross_game_risk', 'variability_composite']\n",
    "    available_enhanced = [f for f in enhanced_features if f in df.columns]\n",
    "    all_features.extend(available_enhanced)\n",
    "    \n",
    "    print(f\"\\nTotal features for modeling: {len(all_features)}\")\n",
    "    \n",
    "    model_df = df[df['RG_case'].notna()].copy()\n",
    "    \n",
    "    final_features = []\n",
    "    for feature in all_features:\n",
    "        if feature in model_df.columns:\n",
    "            # Check if feature has reasonable variance\n",
    "            if model_df[feature].dtype in ['int64', 'float64']:\n",
    "                if model_df[feature].std() > 0 and model_df[feature].notna().sum() > 100:\n",
    "                    final_features.append(feature)\n",
    "    \n",
    "    print(f\"Final feature set: {len(final_features)} features\")\n",
    "    \n",
    "    if len(final_features) < 5:\n",
    "        print(\"Not enough valid features for modeling\")\n",
    "        return None, None, None\n",
    "    \n",
    "    X = model_df[final_features].fillna(0)\n",
    "    y = model_df['RG_case']\n",
    "    \n",
    "    if 'ValidationSet' in model_df.columns:\n",
    "        train_mask = model_df['ValidationSet'] == 0\n",
    "        X_train, X_test = X[train_mask], X[~train_mask]\n",
    "        y_train, y_test = y[train_mask], y[~train_mask]\n",
    "        print(f\"Using existing validation split: {len(X_train)} train, {len(X_test)} test\")\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "        print(f\"Created new split: {len(X_train)} train, {len(X_test)} test\")\n",
    "    \n",
    "    # Train Random Forest (proven best for this problem according to research)\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42,\n",
    "        class_weight='balanced'\n",
    "    )\n",
    "    \n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate model\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    print(f\"\\nModel performance:\")\n",
    "    print(f\"AUC Score: {roc_auc_score(y_test, y_pred_proba):.3f}\")\n",
    "    print(f\"Accuracy: {(y_pred == y_test).mean():.3f}\")\n",
    "    \n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': final_features,\n",
    "        'importance': rf_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nTop 10 most important features:\")\n",
    "    for i, (_, row) in enumerate(feature_importance.head(10).iterrows()):\n",
    "        print(f\"{i+1:2d}. {row['feature']:<30} {row['importance']:.3f}\")\n",
    "    \n",
    "    return rf_model, final_features, feature_importance\n",
    "\n",
    "model, features, importance = build_enhanced_risk_model(df_enhanced, feature_groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f47e644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create risk scoring function\n",
    "\n",
    "def create_risk_scorer(model, features):\n",
    "    if model is None:\n",
    "        return None\n",
    "    \n",
    "    def score_user(user_data):\n",
    "        \"\"\"Score a single user and return risk level + explanation\"\"\"\n",
    "        user_features = []\n",
    "        for feature in features:\n",
    "            value = user_data.get(feature, 0)\n",
    "            user_features.append(value)\n",
    "        \n",
    "        risk_prob = model.predict_proba([user_features])[0][1]\n",
    "        \n",
    "        if risk_prob >= 0.7:\n",
    "            risk_level = \"HIGH\"\n",
    "            color = \"Red\"\n",
    "        elif risk_prob >= 0.4:\n",
    "            risk_level = \"MEDIUM\" \n",
    "            color = \"Yellow\"\n",
    "        else:\n",
    "            risk_level = \"LOW\"\n",
    "            color = \"Green\"\n",
    "        \n",
    "        return {\n",
    "            'risk_probability': risk_prob,\n",
    "            'risk_level': risk_level,\n",
    "            'color': color,\n",
    "            'explanation': f\"Risk factors: {[f for f in features[:3] if user_data.get(f, 0) > 0]}\"\n",
    "        }\n",
    "    \n",
    "    return score_user\n",
    "\n",
    "risk_scorer = create_risk_scorer(model, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8c6de7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced Risk Model Built Successfully\n",
      "Risk Scoring Function Created\n",
      "Ready for Dashboard Integration\n",
      "\n",
      "Sample Risk Assessments\n",
      "--------------------------------------------------\n",
      "\n",
      "User 1: Red HIGH Risk\n",
      "  Probability: 0.930\n",
      "  Actual Outcome: RG Case\n",
      "  Harvard Risk Group: 1\n",
      "\n",
      "User 2: Green LOW Risk\n",
      "  Probability: 0.256\n",
      "  Actual Outcome: Control\n",
      "  Harvard Risk Group: 0\n",
      "\n",
      "User 3: Yellow MEDIUM Risk\n",
      "  Probability: 0.597\n",
      "  Actual Outcome: RG Case\n",
      "  Harvard Risk Group: 0\n"
     ]
    }
   ],
   "source": [
    "# Demo the system\n",
    "\n",
    "if model is not None:\n",
    "    print(\"Enhanced Risk Model Built Successfully\")\n",
    "    print(\"Risk Scoring Function Created\")\n",
    "    print(\"Ready for Dashboard Integration\")\n",
    "    \n",
    "    print(f\"\\nSample Risk Assessments\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    sample_users = df_enhanced.sample(3) if len(df_enhanced) > 0 else []\n",
    "    for i, (_, user) in enumerate(sample_users.iterrows()):\n",
    "        if risk_scorer:\n",
    "            user_dict = user.to_dict()\n",
    "            assessment = risk_scorer(user_dict)\n",
    "            actual_outcome = \"RG Case\" if user['RG_case'] == 1 else \"Control\"\n",
    "            \n",
    "            print(f\"\\nUser {i+1}: {assessment['color']} {assessment['risk_level']} Risk\")\n",
    "            print(f\"  Probability: {assessment['risk_probability']:.3f}\")\n",
    "            print(f\"  Actual Outcome: {actual_outcome}\")\n",
    "            print(f\"  Harvard Risk Group: {user.get('RiskGroupCombined', 'Unknown')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
