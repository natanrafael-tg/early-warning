{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e9eb5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fe8da45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Loaded ../../early/AnalyticDataSet_Braverman_LaPlante_PAB_2013.dat.txt with \t delimiter\n",
      "Loaded ../../trigger/AnalyticDataset_Gray_LaPlante_PAB_2012.dat.txt with \t delimiter\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "\n",
    "def load_dataset(filepath, delimiter='\\t'):\n",
    "    try:\n",
    "        \n",
    "        df = pd.read_csv(filepath, delimiter=delimiter, low_memory=False)\n",
    "        print(f\"Loaded {filepath} with {delimiter} delimiter\")\n",
    "        return df\n",
    "    except:\n",
    "        try:\n",
    "            df = pd.read_csv(filepath, delimiter=',', low_memory=False)\n",
    "            print(f\"Loaded {filepath} with comma delimiter\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load {filepath}: {e}\")\n",
    "            return None\n",
    "\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "# Dataset 1: Early detection (31-day behavioral markers)\n",
    "early_detection_path = \"../../early/AnalyticDataSet_Braverman_LaPlante_PAB_2013.dat.txt\"\n",
    "df_early = load_dataset(early_detection_path)\n",
    "\n",
    "# Dataset 2: Full history (complete behavioral journey)  \n",
    "full_history_path = \"../../trigger/AnalyticDataset_Gray_LaPlante_PAB_2012.dat.txt\"\n",
    "df_full = load_dataset(full_history_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80bb7465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "DATASET: Early Detection (31-day)\n",
      "==================================================\n",
      "Shape: (4056, 114)\n",
      "Columns: 114\n",
      "\n",
      "First 3 rows:\n",
      "    USERID age gender  RG_case  ValidationSet first_active_product1_31days  \\\n",
      "0  5671284  25      1        0              0                   12/23/2007   \n",
      "1  6408486  37      2        0              0                    5/10/2008   \n",
      "2  2044508  25      1        1              0                   10/22/2005   \n",
      "\n",
      "  first_active_product2_31days first_active_product4_31days  \\\n",
      "0                                                             \n",
      "1                                                             \n",
      "2                   10/23/2005                                \n",
      "\n",
      "  first_active_games_31days first_active_poker_31days  ...  \\\n",
      "0                                                      ...   \n",
      "1                                                      ...   \n",
      "2                                                      ...   \n",
      "\n",
      "   p1wkendsumstakesratio  p2wkendsumstakesratio  pcwkendsumstakesratio  \\\n",
      "0                      1                                                 \n",
      "1                      1                                                 \n",
      "2                      1       .847999648096422                          \n",
      "\n",
      "  period_tillDeposit RiskGroup1  RiskGroup2  RiskGroupCombined  \\\n",
      "0                  0          0           0                  0   \n",
      "1                  0          0           0                  0   \n",
      "2                  0          0           0                  0   \n",
      "\n",
      "   totalactivedays_31days totalactivedaystillDeposit_31days_max filter_$  \n",
      "0                       1                                     0        0  \n",
      "1                       1                                     0        0  \n",
      "2                       4                                     0        0  \n",
      "\n",
      "[3 rows x 114 columns]\n",
      "\n",
      "Column Overview:\n",
      "Columns: ['USERID', 'age', 'gender', 'RG_case', 'ValidationSet', 'first_active_product1_31days', 'first_active_product2_31days', 'first_active_product4_31days', 'first_active_games_31days', 'first_active_poker_31days']...\n",
      "\n",
      "Missing Data:\n",
      "                              Missing_Count  Missing_Percentage\n",
      "USERID                                    0                 0.0\n",
      "age                                       0                 0.0\n",
      "gender                                    0                 0.0\n",
      "RG_case                                   0                 0.0\n",
      "ValidationSet                             0                 0.0\n",
      "first_active_product1_31days              0                 0.0\n",
      "first_active_product2_31days              0                 0.0\n",
      "first_active_product4_31days              0                 0.0\n",
      "first_active_games_31days                 0                 0.0\n",
      "first_active_poker_31days                 0                 0.0\n",
      "\n",
      "==================================================\n",
      "DATASET: Full History (Complete Journey)\n",
      "==================================================\n",
      "Shape: (4132, 97)\n",
      "Columns: 97\n",
      "\n",
      "First 3 rows:\n",
      "   UserID  RG_case  Missing_Daily_Transactions First_Deposit_Date  \\\n",
      "0   31965        1                           0           5/8/2000   \n",
      "1   32639        0                           0         11/21/2002   \n",
      "2   36822        0                           0           5/8/2000   \n",
      "\n",
      "  Registration_date  CountryName LanguageName Gender YearofBirth  \\\n",
      "0         9/17/1999  Germany.COM       German      M        1971   \n",
      "1         10/3/1999      Austria       German      M        1969   \n",
      "2         3/20/2000      Austria       German      M        1970   \n",
      "\n",
      "  age_at_registration  ... percent_lost_liveaction_sqrt_zeros  \\\n",
      "0                  27  ...                   2.85173635500845   \n",
      "1                  29  ...                                  3   \n",
      "2                  29  ...                   2.64023357552572   \n",
      "\n",
      "  sum_stakes_casino_sqrt_zeros sum_bets_casino_sqrt_zeros  \\\n",
      "0             142.712473175963           40.8900966005217   \n",
      "1                            0                          0   \n",
      "2                            0                          0   \n",
      "\n",
      "  bettingdays_casino_sqrt_zeros duration_casino_sqrt_zeros  \\\n",
      "0              4.24264068711928           36.2904946232481   \n",
      "1                             0                          0   \n",
      "2                             0                          0   \n",
      "\n",
      "  frequency_casino_sqrt_zeros bets_per_day_casino_sqrt_zeros  \\\n",
      "0            .116907766928076               9.63788819653397   \n",
      "1                           0                              0   \n",
      "2                           0                              0   \n",
      "\n",
      "  euros_per_bet_casino_sqrt_zeros net_loss_casino_sqrt_zeros  \\\n",
      "0                 3.4901476161869           191.729627340169   \n",
      "1                               0                          0   \n",
      "2                               0                          0   \n",
      "\n",
      "  percent_lost_casino_sqrt_zeros  \n",
      "0               2.65416550443384  \n",
      "1                              0  \n",
      "2                              0  \n",
      "\n",
      "[3 rows x 97 columns]\n",
      "\n",
      "Column Overview:\n",
      "Columns: ['UserID', 'RG_case', 'Missing_Daily_Transactions', 'First_Deposit_Date', 'Registration_date', 'CountryName', 'LanguageName', 'Gender', 'YearofBirth', 'age_at_registration']...\n",
      "\n",
      "Missing Data:\n",
      "                            Missing_Count  Missing_Percentage\n",
      "UserID                                  0                 0.0\n",
      "RG_case                                 0                 0.0\n",
      "Missing_Daily_Transactions              0                 0.0\n",
      "First_Deposit_Date                      0                 0.0\n",
      "Registration_date                       0                 0.0\n",
      "CountryName                             0                 0.0\n",
      "LanguageName                            0                 0.0\n",
      "Gender                                  0                 0.0\n",
      "YearofBirth                             0                 0.0\n",
      "age_at_registration                     0                 0.0\n"
     ]
    }
   ],
   "source": [
    "# Basic Data Overview\n",
    "\n",
    "def explore_dataset(df, name):\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"DATASET: {name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    if df is None:\n",
    "        print(\"Dataset not loaded\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {len(df.columns)}\")\n",
    "    \n",
    "    print(f\"\\nFirst 3 rows:\")\n",
    "    print(df.head(3))\n",
    "    \n",
    "    print(f\"\\nColumn Overview:\")\n",
    "    print(f\"Columns: {list(df.columns[:10])}{'...' if len(df.columns) > 10 else ''}\")\n",
    "    \n",
    "    print(f\"\\nMissing Data:\")\n",
    "    missing = df.isnull().sum()\n",
    "    missing_pct = (missing / len(df)) * 100\n",
    "    missing_summary = pd.DataFrame({\n",
    "        'Missing_Count': missing,\n",
    "        'Missing_Percentage': missing_pct\n",
    "    }).sort_values('Missing_Count', ascending=False)\n",
    "    print(missing_summary.head(10))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Explore datasets\n",
    "df_early = explore_dataset(df_early, \"Early Detection (31-day)\")\n",
    "df_full = explore_dataset(df_full, \"Full History (Complete Journey)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8011de7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "KEY VARIABLES ANALYSIS: Early Detection\n",
      "==================================================\n",
      "\n",
      "Case vs Control Distribution:\n",
      "Controls (0): 2014\n",
      "RG Cases (1): 2042\n",
      "RG Case Rate: 50.3%\n",
      "\n",
      "Risk group variables found:\n",
      "RiskGroup1: {0: 3880, 1: 176}\n",
      "RiskGroup2: {0: 3813, 1: 243}\n",
      "RiskGroupCombined: {0: 3637, 1: 419}\n",
      "\n",
      "Variability measures (key predictors):\n",
      "\n",
      "==================================================\n",
      "KEY VARIABLES ANALYSIS: Full History\n",
      "==================================================\n",
      "\n",
      "Case vs Control Distribution:\n",
      "Controls (0): 2066\n",
      "RG Cases (1): 2066\n",
      "RG Case Rate: 50.0%\n",
      "\n",
      "Loss/Hold variables (loss-chasing detection):\n"
     ]
    }
   ],
   "source": [
    "# Key Variables Analysis\n",
    "\n",
    "def analyze_key_variables(df, dataset_name):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"KEY VARIABLES ANALYSIS: {dataset_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    if df is None:\n",
    "        return\n",
    "    \n",
    "    # Looking for RG case distribution\n",
    "    if 'RG_case' in df.columns:\n",
    "        print(\"\\nCase vs Control Distribution:\")\n",
    "        rg_dist = df['RG_case'].value_counts()\n",
    "        print(f\"Controls (0): {rg_dist.get(0, 0)}\")\n",
    "        print(f\"RG Cases (1): {rg_dist.get(1, 0)}\")\n",
    "        print(f\"RG Case Rate: {(rg_dist.get(1, 0) / len(df)) * 100:.1f}%\")\n",
    "    \n",
    "    # Looking for risk group variables (from early detection dataset)\n",
    "    risk_cols = [col for col in df.columns if 'risk' in col.lower()]\n",
    "    if risk_cols:\n",
    "        print(f\"\\nRisk group variables found:\")\n",
    "        for col in risk_cols:\n",
    "            if df[col].dtype in ['int64', 'float64']:\n",
    "                print(f\"{col}: {df[col].value_counts().to_dict()}\")\n",
    "    \n",
    "    # Looking for variability measures (key predictors)\n",
    "    variability_cols = [col for col in df.columns if 'SD' in col or 'variability' in col.lower()]\n",
    "    if variability_cols:\n",
    "        print(f\"\\nVariability measures (key predictors):\")\n",
    "        for col in variability_cols[:5]:\n",
    "            if df[col].dtype in ['int64', 'float64']:\n",
    "                print(f\"{col}: mean={df[col].mean():.2f}, std={df[col].std():.2f}\")\n",
    "    \n",
    "    # Looking for loss/hold variables (for loss-chasing)\n",
    "    loss_cols = [col for col in df.columns if 'loss' in col.lower() or 'hold' in col.lower()]\n",
    "    if loss_cols:\n",
    "        print(f\"\\nLoss/Hold variables (loss-chasing detection):\")\n",
    "        for col in loss_cols[:5]:\n",
    "            if df[col].dtype in ['int64', 'float64']:\n",
    "                print(f\"{col}: mean={df[col].mean():.2f}\")\n",
    "\n",
    "# Analyze key variables in both datasets\n",
    "analyze_key_variables(df_early, \"Early Detection\")\n",
    "analyze_key_variables(df_full, \"Full History\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e56c687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "DATA QUALITY: Early Detection\n",
      "==============================\n",
      "Duplicate UserIDs: 1\n",
      "Unique Users: 4055\n",
      "\n",
      "Data Types Summary:\n",
      "int64      58\n",
      "float64    31\n",
      "object     25\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric Columns Range Check:\n",
      "USERID: [32639.00, 9859152.00]\n",
      "RG_case: [0.00, 1.00]\n",
      "ValidationSet: [0.00, 1.00]\n",
      "p1sumstake31days: [0.00, 31150.03]\n",
      "p1sumbets31days: [0.00, 6651.00]\n",
      "\n",
      "==============================\n",
      "DATA QUALITY: Full History\n",
      "==============================\n",
      "Duplicate UserIDs: 0\n",
      "Unique Users: 4132\n",
      "\n",
      "Data Types Summary:\n",
      "object    94\n",
      "int64      3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Numeric Columns Range Check:\n",
      "UserID: [31965.00, 9859152.00]\n",
      "RG_case: [0.00, 1.00]\n",
      "Missing_Daily_Transactions: [0.00, 1.00]\n",
      "\n",
      "============================================================\n",
      "NEXT STEPS:\n",
      "============================================================\n",
      "1. Data loaded and explored\n",
      "2. Identify key predictive features\n",
      "3. Build risk score model\n",
      "4. Create early warning dashboard\n",
      "5. Demo preparation\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Check\n",
    "\n",
    "def data_quality_check(df, name):\n",
    "    print(f\"\\n{'='*30}\")\n",
    "    print(f\"DATA QUALITY: {name}\")\n",
    "    print(f\"{'='*30}\")\n",
    "    \n",
    "    if df is None:\n",
    "        return\n",
    "    \n",
    "    # Checking for duplicate user IDs\n",
    "    if 'USERID' in df.columns or 'UserID' in df.columns:\n",
    "        userid_col = 'USERID' if 'USERID' in df.columns else 'UserID'\n",
    "        duplicates = df[userid_col].duplicated().sum()\n",
    "        print(f\"Duplicate UserIDs: {duplicates}\")\n",
    "        print(f\"Unique Users: {df[userid_col].nunique()}\")\n",
    "    \n",
    "    # Checking data types\n",
    "    print(f\"\\nData Types Summary:\")\n",
    "    dtype_summary = df.dtypes.value_counts()\n",
    "    print(dtype_summary)\n",
    "    \n",
    "    # Checking for obvious data issues\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        print(f\"\\nNumeric Columns Range Check:\")\n",
    "        for col in numeric_cols[:5]:\n",
    "            print(f\"{col}: [{df[col].min():.2f}, {df[col].max():.2f}]\")\n",
    "\n",
    "data_quality_check(df_early, \"Early Detection\")\n",
    "data_quality_check(df_full, \"Full History\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NEXT STEPS:\")\n",
    "print(\"=\"*60)\n",
    "print(\"1. Data loaded and explored\")\n",
    "print(\"2. Identify key predictive features\")\n",
    "print(\"3. Build risk score model\")\n",
    "print(\"4. Create early warning dashboard\")\n",
    "print(\"5. Demo preparation\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
